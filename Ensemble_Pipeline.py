# -*- coding: utf-8 -*-
"""Ensemble_train_test.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WFr8XHSsQFtPD16ANpyg7NX67xQwdcJo
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset,DataLoader
import torch.optim as optim

import yfinance as yf
from collections import deque
import random
import math
from tqdm import tqdm

dataset_dir = "/content/drive/MyDrive/Deep_RL_for_Stock_Trading"

# Define the ticker symbol for NIFTY50
nifty50_ticker = "^NSEI"

# Download the historical data for NIFTY50
nifty50_data = yf.download(nifty50_ticker, start="2010-01-01", end="2019-08-08")

plt.plot(nifty50_data['Close'])
plt.show()

file_name = f"{dataset_dir}/data.csv"

# Save the DataFrame to a CSV file
nifty50_data.to_csv(file_name, index=False)

print(f"File Saved at {file_name}")

#Data Cleaning and EDA
null_values = nifty50_data.isna().values.any()
print(f"Presence of Null value : {int(null_values)}")

if null_values:
  nifty50_data = nifty50_data.fillna(method = "ffill")

#data splitting in 80-20% fashion for training and testing
X=list(nifty50_data["Close"])
data=[float(x) for x in X]
test_size = 0.2

train_data = data[:int(len(data)*(1-test_size))]
test_data = data[int(len(data)*(1-test_size)):]

print(f"Training Data shape : {len(train_data)} and Testing Data Shape : {len(test_data)}")

#final ensemble model
from collections import Counter

def weighted_vote(actions, buy_weight=3, sell_weight=3):
    weighted_actions = []
    for action in actions:
        if action == 1:  # 'Buy' action
            weighted_actions.extend([action] * int(buy_weight))
        elif action == 2:  # 'Sell' action
            weighted_actions.extend([action] * int(sell_weight))
        else:
            weighted_actions.append(action)

    # Use Counter to find the majority action
    action_counts = Counter(weighted_actions)
    final_action = action_counts.most_common(1)[0][0]

    return final_action

actions = [0, 2, 1]
final_action = weighted_vote(actions)

#agent is already defined in the training set above.
l_test = len(test_data) - 1
state = getState(test_data, 0, window_size + 1)
total_profit = 0
is_eval = True
done = False
states_sell_test = []
states_buy_test = []

#Get the trained model
model_name_1 = f"{dataset_dir}/model_ep8"
agent_1 = DQN_Agent(window_size, is_eval, model_name_1)

model_name = f"{dataset_dir}/model_ddqn_ep8"
agent_2 = DDQN_Agent(window_size, is_eval, model_name)

model_name = f"{dataset_dir}/model_ddpg_ep8"
agent_3 = DDPG_Agent(window_size, is_eval, model_name)

state = getState(data, 0, window_size + 1)
total_profit = 0
agent_inventory = []

for t in tqdm(range(l_test), desc = "Testing Pipeline in progress"):
    actions_1 = agent_1.act(state)
    actions_2 = agent_2.act(state)
    noise = agent_3.noise_generator.sample()
    action_3 = agent_3.act(state, noise)
    actions_3 = np.argmax(action_3)

    action = [actions_1, actions_2, actions_3]
    actions = weighted_vote(action)
    next_state = getState(test_data, t + 1, window_size + 1)
    reward = 0

    if actions == 1:
        agent_inventory.append(test_data[t])
        states_buy_test.append(t)
        print(f"Buy:{test_data[t]}")

    elif actions == 2 and len(agent_inventory) > 0:
        bought_price = agent_inventory.pop(0)
        reward = max(test_data[t] - bought_price, 0)

        total_profit += test_data[t] - bought_price
        states_sell_test.append(t)
        print(f"Sell: {test_data[t]} | profit: {test_data[t] - bought_price}")

    if t == l_test - 1:
        done = True
    agent.memory.append((state, action, reward, next_state, done))
    state = next_state

    if done:
        print("------------------------------------------")
        print(f"Total Profit: {total_profit:.2f}")
        print("------------------------------------------")

plot_behavior(test_data,states_buy_test, states_sell_test, total_profit)
